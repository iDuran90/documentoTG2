\chapter{Evaluación de Clasificadores}
Después de tener cargado el nuevo almacenamiento de datos con la información homogeneizada, se procedió a evaluar los algoritmos de clasificación para elegir los más confiables para construir la interfaz de consultas, que permita conocer los posibles resultados de un evaluado.

El objetivo de este trabajo de grado era entregar información sobre los posibles resultados de un estudiante en cada una de las áreas académicas evaluadas por la prueba Saber 11\degree. Estas áreas son en total 14, así que para cada una de estas áreas se debió construir un clasificador que predijera con el mayor índice de confianza el resultado a obtener por el evaluado. (En el anexo D se encuentra información sobre como interpretar los resultados de la prueba).
\section{Selección de atributos}
El primer paso para la construcción de estos clasificadores fue filtrar la cantidad de atributos predictores disponibles. Al momento de realizar esta fase se contaba con 78 atributos predictores, varios de estos atributos constaban con una gran cantidad de registros nulos, ya que la frecuencia con la que se almacenó en las bases de datos fue muy baja.

Para la selección de estos atributos a ser filtrados se evaluó primero la cantidad de veces en las que este fue registrado, y utilizando la suite de algoritmos de minera de datos Weka\footnote{\url{http://www.cs.waikato.ac.nz/ml/weka/}} se realizó un filtro de selección de atributos utilizando algoritmos especializados para esta tarea.
\subsection{Selección manual}
La tabla \ref{tab:cuadro15} muestra los atributos que se seleccionaron de manera manual, el criterio para esta primera selección fue que al menos estuvieran presentes en 12 (50\%) de las bases de datos consultadas.

\begin{table}[!Hhtb]
\centering
\begin{tabular}{|p{0.5cm}|p{8cm}|p{1.8cm}|}
\hline
	\rowcolor[gray]{0.9} 
	\textbf{ID} &
	\textbf{Atributo} &
	\textbf{Cantidad}\\
\hline
4 & COLE_CODIGO_MCPIO* & 24 \\ \hline
6 & COLE\_INST\_JORNADA & 24 \\ \hline
7 & COLE\_INST\_VLR\_PENSION & 24 \\ \hline
36 & ESTU\_DISC\_MOTRIZ & 24 \\ \hline
37 & ESTU\_DISC\_SORDO\_CON\_INTERPRETE & 24 \\ \hline
38 & ESTU\_DISC\_SORDO\_SIN\_INTERPRETE & 24 \\ \hline
41 & ESTU\_EDAD & 24 \\ \hline
47 & ESTU\_GENERO & 24 \\ \hline
35 & ESTU\_DISC\_INVIDENTE & 22 \\ \hline
44 & ESTU\_EXAM\_DEPTO\_PRESENTACION & 22 \\ \hline
51 & ESTU\_RESIDE\_DEPTO & 22 \\ \hline
1 & COLE\_CALENDARIO\_COLEGIO & 17 \\ \hline
2 & COLE\_CARACTER\_COLEGIO & 17 \\ \hline
48 & ESTU\_IES\_RAZON\_DESEADA & 17 \\ \hline
49 & ESTU\_CARR\_RAZON\_DESEA & 17 \\ \hline
55 & ESTU\_TRABAJA & 17 \\ \hline
58 & FAMI\_COD\_EDUCA\_MADRE & 17 \\ \hline
59 & FAMI\_COD\_EDUCA\_PADRE & 17 \\ \hline
60 & FAMI\_COD\_OCUP\_MADRE & 17 \\ \hline
61 & FAMI\_COD\_OCUP\_PADRE & 17 \\ \hline
63 & FAMI\_ING\_FMILIAR\_MENSUAL & 17 \\ \hline
68 & FAMI\_NUM\_PERS\_GRUP\_FAM & 17 \\ \hline
3 & COLE\_DEPTO\_COLEGIO & 16 \\ \hline
5 & COLE\_IDIOMA\_COLEGIO & 15 \\ \hline
43 & ESTU\_ETNIA & 15 \\ \hline
46 & ESTU\_EXAM\_MPIO\_PRESENTACION & 15 \\ \hline
52 & ESTU\_RESIDE\_MPIO & 15 \\ \hline
54 & ESTU\_TIPO\_DOC & 14 \\ \hline
\end{tabular}
\caption{Atributos predictores seleccionados de manera manual.}
\label{tab:cuadro15}
\end{table}
\begin{quote}
* Originalmente el atributo registrado 24 veces era COLE_INST_NOMBRE, pero como este tenía alrededor de 12500 opciones, se volvió complicado trabajar con él, por lo tanto se decidió utilizar este para conocer el municipio al que el colegio pertenece y así el atributo COLE_CODIGO_MCPIO se pudo registrar las 24 veces.
\end{quote}
Tras aplicar este primer filtro la cantidad de atributos predictores considerados útiles, se redujo a 28.
Después, usando estos 28 atributos, se procedió a utilizar los algoritmos de selección de atributos predictores disponibles en Weka.
\subsection{Selección automática}
Weka brinda la capacidad de realizar esta selección de atributos utilizando métodos evaluadores que se dividen en 2 tipos: los evaluadores de subconjuntos y los prorrateadores de atributos. El primer tipo se encarga de evaluar cual subconjunto de datos es el mejor para predecir la clase, este utiliza un método de búsqueda del tipo forward o backward. El segundo tipo no evalúa subconjuntos, si no que asigna a cada atributo un valor que indica el nivel de correlación que posee con la clase a predecir, este al contrario de utilizar un método de búsqueda, utiliza un ranker para indicar la importancia de cada atributo.

El primer paso para poder utilizar Weka fue construir los archivos arff\footnote{\url{http://weka.wikispaces.com/ARFF}} estos son los archivos que usa Weka para transmitir la información a los algoritmos. En la primera prueba se construyó un archivo arff con 1000 registros, con los datos obtenidos desde el almacenamiento de datos construido en el capítulo anterior. La idea de realizar esta prueba inicial era determinar los tiempos que demoraba cada posible combinación entre los métodos de evaluación y los métodos de búsqueda que ofrece Weka. Después de realizar esta prueba se optó por la utilización de 6 combinaciones que fueron las que lograron manipular la cantidad de datos presentados, en un tiempo aceptable, teniendo en cuenta que más adelante se ejecutarían pruebas con archivos que contenían hasta 500.000 registros.

La razón para que algunas combinaciones no fueran seleccionadas, fue porque nunca se logró obtener una solución en el tiempo otorgado (20 minutos) o lanzaron error al momento de procesar el archivo. El tiempo de 20 minutos, fue tomado como un límite justificable, ya que de los algoritmos de los cuales si se obtuvo respuesta, no tomaron un tiempo mayor a 3 minutos.

La tabla \ref{tab:cuadro16} muestra las combinaciones seleccionadas.

Como ya se explicó que se construyó un clasificador por cada área evaluada, la selección de atributos también se aplicó a cada una de estas clases a predecir, es decir que por cada área se crearon los archivos arff para ser analizados en los algoritmos.

Los archivos ARFF creados para realizar cada prueba fueron construidos seleccionando de manera aleatoria registros de la base de datos homogeneizada. Además estos archivos fueron creados con distintas cantidades de registros, con el fin de tener una mejor visión sobre el comportamiento de los algoritmos a medida que se aumentaba la cantidad de registros. Estas cantidades fueron 1.000, 10.000, 100.000 y 500.000. Es decir, por cada área evaluada se crearon 4 archivos arff que fueron ejecutados en las 6 combinaciones distintas, dando así 24 evaluaciones a analizar. 

\begin{table}[!Hhtb]
\centering
\begin{tabular}{|p{1cm}|p{6cm}|p{6cm}|}
\hline
	\rowcolor[gray]{0.9}
	\textbf{ID} &
	\textbf{Método de evaluación} &
	\textbf{Método de búsqueda}\\
\hline
1 & CfsSubsetEval\protect\footnotemark & BestFirst\protect\footnotemark \\ \hline
2 & CfsSubsetEval  & GeneticSearch\protect\footnotemark  \\ \hline
3 & CfsSubsetEval  & GreedyStepwise\protect\footnotemark \\ \hline
4 & ClassifierSubsetEval\protect\footnotemark & GeneticSearch \\ \hline
5 & GainRatioAttributeEval\protect\footnotemark & Ranker\protect\footnotemark \\ \hline
6 & InfoGainAttributeEval\protect\footnotemark & Ranker  \\ \hline
\end{tabular}
\caption{Combinaciones utilizadas en Weka para seleccionar atributos predictores.}
\label{tab:cuadro16}
\end{table}
\addtocounter{footnote}{-7}
\footnotetext{\url{http://weka.sourceforge.net/doc.stable/weka/attributeSelection/CfsSubsetEval.html}}
\addtocounter{footnote}{1}
\footnotetext{\url{http://weka.sourceforge.net/doc.stable/weka/attributeSelection/BestFirst.html}}
\addtocounter{footnote}{1}
\footnotetext{\url{http://weka.sourceforge.net/doc.stable/weka/attributeSelection/GeneticSearch.html}}
\addtocounter{footnote}{1}
\footnotetext{\url{http://weka.sourceforge.net/doc.stable/weka/attributeSelection/GreedyStepwise.html}}
\addtocounter{footnote}{1}
\footnotetext{\url{http://weka.sourceforge.net/doc.stable/weka/attributeSelection/ClassifierSubsetEval.html}}
\addtocounter{footnote}{1}
\footnotetext{\url{http://weka.sourceforge.net/doc.stable/weka/attributeSelection/GainRatioAttributeEval.html}}
\addtocounter{footnote}{1}
\footnotetext{\url{http://weka.sourceforge.net/doc.stable/weka/attributeSelection/Ranker.html}}
\addtocounter{footnote}{1}
\footnotetext{\url{http://weka.sourceforge.net/doc.stable/weka/attributeSelection/InfoGainAttributeEval.html}}
\section{Creación de vistas minables}
Posterior a la ejecución de los algoritmos de selección automática, se reevaluó la calidad de los atributos predictores y su capacidad de ser realmente aportantes al momento de predecir el posible puntaje en un área académica. Se decidió que los atributos ESTU_EXAM_MPIO_PRESENTACION y ESTU_EXAM_DEPTO_PRESENTACION no serían tenidos en cuenta para la construcción de los clasificadores, ya que al analizar la base de datos, en más del 90\% de los casos el valor de estos 2 atributos era equivalente al valor de los atributos COLE_CODIGO_MCPIO y COLE_DEPTO_COLEGIO respectivamente, por lo tanto se generaba redundancia en los datos y esto ocasiona que la calidad de las predicciones disminuya. 

También el atributo ESTU_TIPO_DOC que indica el tipo de documento con el que la persona se inscribió, no entregaba información realmente útil. Al analizar la base de datos alrededor del 95\% de los registros se dividían entre ``Tarjeta de Identidad'' o “Cedula de Ciudadanía”, los otros valores posibles no eran comunes. Este atributo se solapa con el atributo ESTU_EDAD, ya que el valor “Tarjeta de Identidad” los tenían los evaluados menores de 18 años y “Cedula de Ciudadanía” los evaluadores mayores de 18 años. Por lo tanto, es claro que conociendo la edad de un evaluado, se puede conocer qué tipo de documento utiliza, así que la edad absorbió este atributo y por eso no fue tenido en cuenta a la hora de construir los clasificadores.

Después de analizar los resultados de la ejecución de los algoritmo de selección de atributos, se procedió a construir las vistas minables que iban a ser procesadas en cada uno de los algoritmos de construcción de clasificadores.

Para la construcción de estas vista minables, se realizó una selección entre los 28 atributos filtrados inicialmente y los atributos que tuvieron una mayor presencia en los resultados de los algoritmos de selección de atributos. En algunas áreas se crearon 2 vistas minables para tener una mejor perspectiva, respecto a distintos comportamientos. No se definió un límite mínimo de selección de los atributos en los resultados de los algoritmos, la cantidad de atributos que compone cada vista minable se decidió teniendo en cuenta el número de veces que fue seleccionado el más frecuente.

Los procesos de minería de datos involucran, además de los algoritmos, el conocimiento que se tenga sobre el problema, en ocasiones algunos atributos pueden no ser relevantes al momento de ejecutar los algoritmos, pero es conocido por las personas involucradas en el proceso, que estos atributos sí determinan un factor importante en el caso de estudio. Teniendo en cuenta este criterio, algunos atributos que tuvieron poca relevancia en los algoritmos de selección, fueron escogidos para ser predictores, ya que se consideró que su significado podría beneficiar la calidad de las predicciones.

La tabla \ref{tab:cuadro31} muestra los atributos procesados en los algoritmos de selección de atributos, para el caso del área de biología, y la frecuencia con la que los algoritmos de selección le dieron importancia. Cabe aclarar que en el caso de los algoritmos de evaluación que utilizan un método de búsqueda “Ranker” siempre aparecieron todos los valores, pero la puntuación asignada a algunos de ellos era de 0.0 por lo tanto estos no se contaron como atributos seleccionados por ese algoritmo.

\begin{table}[!Hhtb]
\centering
\begin{tabular}{|p{1cm}|p{8cm}|p{3cm}|}
\hline
	\rowcolor[gray]{0.9}
	\textbf{ID} &
	\textbf{Atributo} &
	\textbf{\# de veces que se seleccionó}\\
\hline
58    & FAMI_COD_EDUCA_MADRE & 19 \\
\hline
4     & COLE_CODIGO_MCPIO & 17 \\
\hline
41    & ESTU_EDAD & 17 \\
\hline
63    & FAMI_ING_FMILIAR_MENSUAL & 17 \\
\hline
6     & COLE_INST_JORNADA & 16 \\
\hline
52    & ESTU_RESIDE_MPIO & 16 \\
\hline
7     & COLE_INST_VLR_PENSION & 15 \\
\hline
59    & FAMI_COD_EDUCA_PADRE & 15 \\
\hline
60    & FAMI_COD_OCUP_MADRE & 15 \\
\hline
51    & ESTU_RESIDE_DEPTO & 12 \\
\hline
3     & COLE_DEPTO_COLEGIO & 8 \\
\hline
38    & ESTU_DISC_SORDO_SIN_INTERPRETE & 8 \\
\hline
43    & ESTU_ETNIA & 7 \\
\hline
61    & FAMI_COD_OCUP_PADRE & 7 \\
\hline
5     & COLE_IDIOMA_COLEGIO & 6 \\
\hline
47    & ESTU_GENERO & 6 \\
\hline
49    & ESTU_CARR_RAZON_DESEA & 6 \\
\hline
48    & ESTU_IES_RAZON_DESEADA & 5 \\
\hline
36    & ESTU_DISC_MOTRIZ & 4 \\
\hline
37    & ESTU_DISC_SORDO_CON_INTERPRETE & 4 \\
\hline
1     & COLE_CALENDARIO_COLEGIO & 3 \\
\hline
35    & ESTU_DISC_INVIDENTE & 3 \\
\hline
2     & COLE_CARACTER_COLEGIO & 2 \\
\hline
68    & FAMI_NUM_PERS_GRUP_FAM & 2 \\
\hline
55    & ESTU_TRABAJA & 1 \\
\hline
\end{tabular}
\caption{Cantidad de veces que los atributos fueron seleccionados como buenos predictores por los algoritmos de selección de atributos, en el área de biología.}
\label{tab:cuadro31}
\end{table}
En la tabla \ref{tab:cuadro31} se observa los atributos ordenados con base a la relevancia que tuvieron en los algoritmos de selección. Para crear las vistas minables se seleccionaron los de mayor frecuencia.

El criterio aplicado, en el caso de biología, a la selección de los atributos fue que estos se encontraran en al menos 12 de las combinaciones, es decir en el 50\% de estas, 10 atributos cumplieron con este criterio.

Después de analizar estos primeros 10 atributos se pudo notar que existían 2 que indicaban la misma información pero con diferente granularidad, estos eran COLE_DEPTO_COLEGIO y COLE_CODIGO_MCPIO, ambos indican la ubicación del colegio, uno a nivel departamental y el otro a nivel municipal, por lo tanto solo era necesario seleccionar uno de ellos para indicar la ubicación del colegio. Pero como los 2 tenían una frecuencia que cumplía con el criterio, se decidió crear 2 vista minables en donde una tuviera una granularidad de departamento en la ubicación del colegio y la otra una granularidad de municipio en la ubicación del colegio.

Así, siguiendo una lógica similar a la aplicada al área de biología, se crearon las vistas minables de las demás áreas académicas.

En las 14 áreas académicas se intentó seguir las mismas reglas de manera general, pero en algunas áreas como por ejemplo medio ambiente, eran pocos los atributos que cumplían con estar seleccionado en al menos 12 combinaciones, en el caso de medio ambiente, solo 3 atributos cumplían esto.
 
También para el caso de algunos atributos, como FAMI_COD_OCUP_PADRE, no tuvieron buena frecuencia de selección, pero FAMI_COD_OCUP_MADRE si lo hizo, teniendo en cuenta que estos indican la misma información de los padres, en algunas vistas minables se agregó la ocupación del padre como atributo a pesar de que su frecuencia de selección no fuera alta.

La tabla \ref{tab:cuadro32} muestra las vistas minables creadas para cada una de las áreas académicas.

\begin{table}[!Hhtb]
\centering
\begin{tabular}{|p{3.5cm}|p{7cm}|}
\hline
	\rowcolor[gray]{0.9} 
	\multicolumn{2}{|c|}{
	\textbf{Vistas minables}}\\
\hline
	\rowcolor[gray]{0.5}
	Nombre & Atributos\\
\hline
Biologia9 & 6, 7, 41, 51, 58, 59, 60, 61, 63 \\
\hline
Biologia10 & 4, 6, 7, 41, 52, 58, 59, 60, 61, 63 \\
\hline
Filosofia7 & 1, 4, 7, 41, 52, 58, 59 \\
\hline
Fisica11 & 1, 4, 7, 41, 47, 52, 58, 59, 60, 61, 63 \\
\hline
Fisica211 & 1, 6, 7, 41, 47, 52, 58, 59, 60, 61, 63 \\
\hline
Ingles11 & 4, 5, 6, 7, 41, 52, 58, 59, 60, 61, 63 \\
\hline
Lenguaje10 & 4, 7, 41, 43, 52, 58, 59, 60, 61, 63 \\
\hline
Lenguaje210 & 4, 6, 7, 41, 43, 58, 59, 60, 61, 63 \\
\hline
Matematica10 & 4, 6, 7, 41, 47, 52, 58, 59, 60, 61 \\
\hline
Matematica210 & 1, 3, 6, 7, 41, 47, 58, 59, 60, 61 \\
\hline
MedioAmbiente5 & 2, 4, 52, 58, 60 \\
\hline
MedioAmbiente7 & 2, 4, 52, 58, 59, 60, 61 \\
\hline
ProBiologia6 & 1, 4, 7, 58, 60, 63 \\
\hline
ProBiologia8 & 1, 4, 7, 58, 59, 60, 61, 63 \\
\hline
ProLenguaje7 & 2, 4, 7, 41, 58, 60, 63 \\
\hline
ProLenguaje9 & 2, 4, 7, 41, 58, 59, 60, 61, 63 \\
\hline
ProMatematica7 & 4, 6, 7, 41, 58, 60, 63 \\
\hline
ProMatematica9 & 4, 6, 7, 41, 58, 59, 60, 61, 63 \\
\hline
ProSociales7 & 1, 4, 7, 41, 58, 60, 63 \\
\hline
ProSociales9 & 1, 4, 7, 41, 58, 59, 60, 61, 63 \\
\hline
Quimica10 & 4, 6, 7, 41, 52, 58, 59, 60, 61, 63 \\
\hline
Sociales7 & 4, 7, 41, 52, 58, 60, 63  \\
\hline
Sociales9 & 4, 7, 41, 52, 58, 59, 60, 61, 63  \\
\hline
ViolenciaSociedad11 & 4, 6, 7, 41, 52, 55, 58, 59, 60, 61, 63 \\
\hline
\end{tabular}
\caption{Lista de las vistas minables creadas.}
\label{tab:cuadro32}
\end{table}
Teniendo lista la estructura para construir las vistas minables, se procedió a la carga de estas. Cada vista minable se creó con 1.000, 10.000 y 100.000 registros.

Las vistas minables se cargaron utilizando el lenguaje de programación Python. Se utilizó el generador de números aleatorios para seleccionar los registros en la base de datos de manera que se aseguró que no existía ninguna correlación entre los registros cargados. También se aseguró que estos registros fueran cargados sin ninguno de sus atributos con valor nulo, esto se hizo con el fin de que los algoritmos de clasificación tuvieran una mejor confiabilidad.

En el caso de las profundizaciones, en donde la cantidad de registros es menor, ya que la presentación de estas pruebas es opcional, no se pudieron crear vistas minables de 100.000 registros, porque fue difícil lograr que todos los atributos coincidieran en no ser nulos, por eso en las profundizaciones los grupos fueron de 1.000, 10.000 y 50.000.

Con las vistas minables cargadas, se procedió a la evaluación de estos en los algoritmos de construcción de clasificadores.
\section{Construcción de clasificadores}
Utilizando Weka, se procedió a generar distintos clasificadores, teniendo en cuenta los trabajos revisados y que sirvieron de apoyo para este, los algoritmos seleccionados para evaluar las vistas minables fueron: generador de árboles de decisión C4.5\footnote{\url{http://weka.sourceforge.net/doc.stable/weka/classifiers/trees/J48.html}}, K vecinos más cercanos\footnote{\url{http://weka.sourceforge.net/doc.stable/weka/classifiers/lazy/IBk.html}}, Naive Bayes\footnote{\url{http://weka.sourceforge.net/doc.stable/weka/classifiers/bayes/NaiveBayes.html}} y la red neuronal RBF (Radial Basis Function)\footnote{\url{ http://weka.sourceforge.net/doc.stable/weka/classifiers/functions/RBFNetwork.html}}.

Weka ofrece la posibilidad de ejecutar cada uno de estos algoritmos con una colección de datos de entrenamiento y evaluar su nivel de confianza con un archivo de evaluación.

Los archivos de entrenamiento fueron aquellos que se crearon siguiendo la estructura de las vistas minables presentadas en la anterior sección. En Weka es posible dividir estos archivos, para que un porcentaje sea de entrenamiento y el otro porcentaje sea de evaluación. Pero en este trabajo se decidió crear los archivos de evaluación a partir de un conjunto de datos completamente nuevo y desconocido para el conjunto de datos de entrenamiento, esto se logró utilizando los resultados de la prueba en el año 2012. 

Como se explicó inicialmente, al momento de empezar este trabajo las bases de datos disponibles eran las de los años 2000 hasta 2011, pero al momento de empezar la creación de los clasificadores, la base de datos del año 2012 estaba disponible para su descarga y se pudo utilizar como un conjunto de datos desconocido para el conjunto de datos inicial.

Para cada vista minable se creó un archivo que tenía la misma estructura pero que se cargaba con registros de la base de datos de 2012, estos archivos de evaluación se crearon con una cantidad de 1000 registros. Es decir que por cada clasificador creado, se evaluaba su precisión y exhaustividad con 1000 registros de los cuales se conocía la clase, pero al clasificador se le presentaba como desconocida, para que la predijera.

Con las evaluaciones de precisión y exhaustividad se pudo visualizar el nivel de confianza que ofrecía cada clasificador, la precisión fue el factor en base al cual se tomó la decisión de cuales clasificadores iban a ser utilizados en la construcción de la interfaz de consultas.

El en anexo A se encuentran las gráficas que muestran los valores de precisión y exhaustividad obtenidos al ejecutar cada una de las vistas minables en cada uno de los algoritmos seleccionados. Para el caso del algoritmo de los k vecinos más cercanos, se realizaron 2 ejecuciones. Una con un valor de k=1 y otra con el valor de k=2, con el fin de encontrar como afecta la selección del valor de k al desempeño del algoritmo.
\section{Selección de los clasificadores}
Teniendo en cuenta los resultados de precisión y exhaustividad que obtuvo cada uno de los clasificadores con cada una de las vistas minables presentadas por las áreas académicas, se eligieron los mejores resultados por cada una.

La elección de los mejores clasificadores en cada vista minable se realizó comparando los valores de precisión y exhaustividad. El criterio más importante fue la precisión, en caso de existir similitud entre 2 o más clasificadores en este valor, entonces se procedía a observar cuál de ellos presentaba una mejor exhaustividad.

Teniendo en cuenta estos criterios y los resultados relacionados en las gráficas del anexo A, se seleccionaron los atributos, la tabla \ref{tab:cuadro38} presenta esta selección.

\clearpage
\begin{table}[!Hhtbp]
\centering
\begin{tabular}{|p{3.5cm}|p{3cm}|p{2cm}|p{3cm}|p{3cm}|}
\hline
	\rowcolor[gray]{0.9} 
	\textbf{Área académica} &
	\textbf{Vista minable} &
	\textbf{Instancias de entrenamiento} &
	\textbf{Algoritmo del clasificador} &
	\textbf{Precisión \& Exhaustividad}
	\\
\hline
Biología & Biologia9 & 100.000 & Naive Bayes & 0.418 \& 0.450 \\
\hline
Ciencias Sociales & Sociales7 & 100.000 & Redes RBF & 0.426	\& 0.469\\
\hline
Filosofía & Filosofia7 & 1.000 & Naive Bayes & 0.375 \& 0.374\\
\hline
Física & Fisica11 & 10.000 & Redes RBF & 0.418 \& 0.408\\
\hline
Ingles & Ingles11 & 10.000 & KNN K=1 & 0.663 \& 0.659\\
\hline
Lenguaje & Lenguaje210 & 1.000 & Naive Bayes & 0.520 \& 0.555\\
\hline
Matemática & Matematica10 & 10.000 & KNN K=2 & 0.339 \& 0.345\\
\hline
Medio Ambiente & MedioAmbiente7 & 10.000 & KNN K=1 & 0.768 \& 0.245 \\
\hline
Profundización en Biología & ProBiologia6 & 50.000 & Redes RBF & 0.406 \& 0.262\\
\hline
Profundización en Lenguaje & ProLenguaje7 & 10.000 & KNN K=1 & 0.405 \& 0.247 \\
\hline
Profundización en Matemática & ProMatematica9 & 50.000 & RBF & 0.604 \& 0.251 \\
\hline
Profundización en Ciencias Sociales & ProSociales7 & 10.000 & Naive Bayes & 0.554 \& 0.214 \\
\hline
Química & Quimica10 & 10.000 & KNN K=2 & 0.544 \& 0.533 \\
\hline
Violencia y Sociedad & Violencia11 & 10.000 & Redes RBF & 0.347 \& 0.374\\
\hline
\end{tabular}
\caption{Clasificadores seleccionados para la construcción de la interfaz de consultas.}
\label{tab:cuadro38}
\end{table}